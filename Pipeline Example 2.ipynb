{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline 1: Data Preparation and Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An easy trap to fall into in applied machine learning is leaking data from your training \n",
    "dataset to your test dataset.\n",
    "\n",
    "To avoid this trap you need a robust test harness with strong separation of training and \n",
    "testing. This includes data preparation.\n",
    "\n",
    "Data preparation is one easy way to leak knowledge of the whole training dataset to the \n",
    "algorithm. For example, preparing your data using normalization or standardization on the\n",
    "entire training dataset before learning would not be a valid test because the training dataset \n",
    "would have been influenced by the scale of the data in the test set.\n",
    "\n",
    "Pipelines help you prevent data leakage in your test harness by ensuring that data preparation \n",
    "like standardization is constrained to each fold of your cross validation procedure.\n",
    "\n",
    "The example below demonstrates this important data preparation and model evaluation workflow. \n",
    "The pipeline is defined with two steps:\n",
    "\n",
    "Standardize the data.\n",
    "Learn a Linear Discriminant Analysis model.\n",
    "The pipeline is then evaluated using 10-fold cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.773462064252\n"
     ]
    }
   ],
   "source": [
    "# Create a pipeline that standardizes the data then creates a model\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "# load data\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/pima-indians-diabetes/pima-indians-diabetes.data\"\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "dataframe = read_csv(url, names=names)\n",
    "array = dataframe.values\n",
    "X = array[:,0:8]\n",
    "Y = array[:,8]\n",
    "\n",
    "# create pipeline\n",
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('lda', LinearDiscriminantAnalysis()))\n",
    "model = Pipeline(estimators)\n",
    "\n",
    "# evaluate pipeline\n",
    "seed = 7\n",
    "kfold = KFold(n_splits=10, random_state=seed)\n",
    "results = cross_val_score(model, X, Y, cv=kfold)\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline 2: Feature Extraction and Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature extraction is another procedure that is susceptible to data leakage.\n",
    "\n",
    "Like data preparation, feature extraction procedures must be restricted to the data in your \n",
    "training dataset.\n",
    "\n",
    "The pipeline provides a handy tool called the FeatureUnion which allows the results of multiple\n",
    "feature selection and extraction procedures to be combined into a larger dataset on which a \n",
    "model can be trained. Importantly, all the feature extraction and the feature union occurs \n",
    "within each fold of the cross validation procedure.\n",
    "\n",
    "The example below demonstrates the pipeline defined with four steps:\n",
    "\n",
    "Feature Extraction with Principal Component Analysis (3 features)\n",
    "Feature Extraction with Statistical Selection (6 features)\n",
    "Feature Union\n",
    "Learn a Logistic Regression Model\n",
    "The pipeline is then evaluated using 10-fold cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.776042378674\n"
     ]
    }
   ],
   "source": [
    "# Create a pipeline that extracts features from the data then creates a model\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "\n",
    "# load data\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/pima-indians-diabetes/pima-indians-diabetes.data\"\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "dataframe = read_csv(url, names=names)\n",
    "array = dataframe.values\n",
    "X = array[:,0:8] # All rows and columns 0 to 7\n",
    "Y = array[:,8] # All rows and column 8\n",
    "\n",
    "# create feature union\n",
    "features = []\n",
    "features.append(('pca', PCA(n_components=3)))\n",
    "features.append(('select_best', SelectKBest(k=6)))\n",
    "feature_union = FeatureUnion(features)\n",
    "\n",
    "# create pipeline\n",
    "estimators = []\n",
    "estimators.append(('feature_union', feature_union))\n",
    "estimators.append(('logistic', LogisticRegression()))\n",
    "model = Pipeline(estimators)\n",
    "\n",
    "# evaluate pipeline\n",
    "seed = 7\n",
    "kfold = KFold(n_splits=10, random_state=seed)\n",
    "results = cross_val_score(model, X, Y, cv=kfold)\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this post you discovered the difficulties of data leakage in applied machine learning.\n",
    "\n",
    "You discovered the Pipeline utilities in Python scikit-learn and how they can be used to \n",
    "automate standard applied machine learning workflows.\n",
    "\n",
    "You learned how to use Pipelines in two important use cases:\n",
    "\n",
    "Data preparation and modeling constrained to each fold of the cross validation procedure.\n",
    "Feature extraction and feature union constrained to each fold of the cross validation procedure.\n",
    "Do you have any questions about data leakage, Pipelines or this post? Ask your questions in the \n",
    "comments and I will do my best to answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
